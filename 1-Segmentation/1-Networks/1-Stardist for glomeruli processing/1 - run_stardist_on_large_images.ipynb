{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdN8B91xZO0x"
   },
   "source": [
    "# **1. Install StarDist and dependencies**\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2uHigbVJ9CUh"
   },
   "source": [
    "## **Load key dependencies**\n",
    "---\n",
    "<font size = 4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10860,
     "status": "ok",
     "timestamp": 1637582467871,
     "user": {
      "displayName": "PABLO DELGADO RODRIGUEZ",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11999848093282927146"
     },
     "user_tz": -60
    },
    "id": "HMAdm-Mc9HFz",
    "outputId": "84d0616e-4605-4256-857a-2b8056ba98b5"
   },
   "outputs": [],
   "source": [
    "#@markdown ##Load key dependencies\n",
    "from __future__ import print_function, unicode_literals, absolute_import, division\n",
    "Notebook_version = '1.13'\n",
    "Network = 'StarDist 2D'\n",
    "\n",
    "from builtins import any as b_any\n",
    "\n",
    "def get_requirements_path():\n",
    "    # Store requirements file in 'contents' directory \n",
    "    current_dir = os.getcwd()\n",
    "    dir_count = current_dir.count('/') - 1\n",
    "    path = '../' * (dir_count) + 'requirements.txt'\n",
    "    return path\n",
    "\n",
    "def filter_files(file_list, filter_list):\n",
    "    filtered_list = []\n",
    "    for fname in file_list:\n",
    "        if b_any(fname.split('==')[0] in s for s in filter_list):\n",
    "            filtered_list.append(fname)\n",
    "    return filtered_list\n",
    "\n",
    "def build_requirements_file(before, after):\n",
    "    path = get_requirements_path()\n",
    "\n",
    "    # Exporting requirements.txt for local run\n",
    "    !pip freeze > $path\n",
    "\n",
    "    # Get minimum requirements file\n",
    "    df = pd.read_csv(path, delimiter = \"\\n\")\n",
    "    mod_list = [m.split('.')[0] for m in after if not m in before]\n",
    "    req_list_temp = df.values.tolist()\n",
    "    req_list = [x[0] for x in req_list_temp]\n",
    "\n",
    "    # Replace with package name and handle cases where import name is different to module name\n",
    "    mod_name_list = [['sklearn', 'scikit-learn'], ['skimage', 'scikit-image']]\n",
    "    mod_replace_list = [[x[1] for x in mod_name_list] if s in [x[0] for x in mod_name_list] else s for s in mod_list] \n",
    "    filtered_list = filter_files(req_list, mod_replace_list)\n",
    "\n",
    "    file=open(path,'w')\n",
    "    for item in filtered_list:\n",
    "        file.writelines(item + '\\n')\n",
    "\n",
    "    file.close()\n",
    "\n",
    "import sys\n",
    "before = [str(m) for m in sys.modules]\n",
    "\n",
    "\n",
    "#%load_ext memory_profiler\n",
    "\n",
    "\n",
    "#%tensorflow_version 1.x\n",
    "\n",
    "import tensorflow\n",
    "print(tensorflow.__version__)\n",
    "print(\"Tensorflow enabled.\")\n",
    "\n",
    "\n",
    "import imagecodecs\n",
    "\n",
    "# ------- Variable specific to Stardist -------\n",
    "from stardist import fill_label_holes, random_label_cmap, calculate_extents, gputools_available, relabel_image_stardist, random_label_cmap,  relabel_image_stardist, _draw_polygons, export_imagej_rois\n",
    "from stardist.models import Config2D, StarDist2D, StarDistData2D # import objects\n",
    "from stardist.matching import matching_dataset\n",
    "\n",
    "from csbdeep.utils import Path, normalize, download_and_extract_zip_file, plot_history # for loss plot\n",
    "from csbdeep.io import save_tiff_imagej_compatible\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "lbl_cmap = random_label_cmap()\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from PIL import Image\n",
    "import zarr\n",
    "from zipfile import ZIP_DEFLATED\n",
    "from csbdeep.data import Normalizer, normalize_mi_ma\n",
    "import imagecodecs\n",
    "\n",
    "\n",
    "class MyNormalizer(Normalizer):\n",
    "    def __init__(self, mi, ma):\n",
    "            self.mi, self.ma = mi, ma\n",
    "    def before(self, x, axes):\n",
    "        return normalize_mi_ma(x, self.mi, self.ma, dtype=np.float32)\n",
    "    def after(*args, **kwargs):\n",
    "        assert False\n",
    "    @property\n",
    "    def do_after(self):\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "# ------- Common variable to all ZeroCostDL4Mic notebooks -------\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import urllib\n",
    "import os, random\n",
    "import shutil \n",
    "import zipfile\n",
    "from tifffile import imread, imsave\n",
    "import time\n",
    "import sys\n",
    "import wget\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import csv\n",
    "from glob import glob\n",
    "from scipy import signal\n",
    "from scipy import ndimage\n",
    "from skimage import io\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from skimage.util import img_as_uint\n",
    "import matplotlib as mpl\n",
    "from skimage.metrics import structural_similarity\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from astropy.visualization import simple_norm\n",
    "from skimage import img_as_float32, img_as_ubyte, img_as_float\n",
    "from skimage.util import img_as_ubyte\n",
    "from tqdm import tqdm \n",
    "import cv2\n",
    "from fpdf import FPDF, HTMLMixin\n",
    "from datetime import datetime\n",
    "from pip._internal.operations.freeze import freeze\n",
    "import subprocess\n",
    "\n",
    "# For sliders and dropdown menu and progress bar\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Colors for the warning messages\n",
    "class bcolors:\n",
    "  WARNING = '\\033[31m'\n",
    "W  = '\\033[0m'  # white (normal)\n",
    "R  = '\\033[31m' # red\n",
    "\n",
    "#Disable some of the tensorflow warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print('------------------------------------------')\n",
    "print(\"Libraries installed\")\n",
    "\n",
    "\n",
    "# Check if this is the latest version of the notebook\n",
    "All_notebook_versions = pd.read_csv(\"https://raw.githubusercontent.com/HenriquesLab/ZeroCostDL4Mic/master/Colab_notebooks/Latest_Notebook_versions.csv\", dtype=str)\n",
    "print('Notebook version: '+Notebook_version)\n",
    "Latest_Notebook_version = All_notebook_versions[All_notebook_versions[\"Notebook\"] == Network]['Version'].iloc[0]\n",
    "print('Latest notebook version: '+Latest_Notebook_version)\n",
    "if Notebook_version == Latest_Notebook_version:\n",
    "  print(\"This notebook is up-to-date.\")\n",
    "else:\n",
    "  print(bcolors.WARNING +\"A new version of this notebook has been released. We recommend that you download it at https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki\")\n",
    "\n",
    "\n",
    "\n",
    "# PDF export\n",
    "\n",
    "def pdf_export(trained=False, augmentation = False, pretrained_model = False):\n",
    "  class MyFPDF(FPDF, HTMLMixin):\n",
    "    pass\n",
    "\n",
    "  pdf = MyFPDF()\n",
    "  pdf.add_page()\n",
    "  pdf.set_right_margin(-1)\n",
    "  pdf.set_font(\"Arial\", size = 11, style='B') \n",
    "\n",
    "  day = datetime.now()\n",
    "  datetime_str = str(day)[0:10]\n",
    "\n",
    "  Header = 'Training report for '+Network+' model ('+model_name+')\\nDate: '+datetime_str\n",
    "  pdf.multi_cell(180, 5, txt = Header, align = 'L') \n",
    "    \n",
    "  # add another cell \n",
    "  if trained:\n",
    "    training_time = \"Training time: \"+str(hour)+ \"hour(s) \"+str(mins)+\"min(s) \"+str(round(sec))+\"sec(s)\"\n",
    "    pdf.cell(190, 5, txt = training_time, ln = 1, align='L')\n",
    "  pdf.ln(1)\n",
    "\n",
    "  Header_2 = 'Information for your materials and method:'\n",
    "  pdf.cell(190, 5, txt=Header_2, ln=1, align='L')\n",
    "\n",
    "  all_packages = ''\n",
    "  for requirement in freeze(local_only=True):\n",
    "    all_packages = all_packages+requirement+', '\n",
    "  #print(all_packages)\n",
    "\n",
    "  #Main Packages\n",
    "  main_packages = ''\n",
    "  version_numbers = []\n",
    "  for name in ['tensorflow','numpy','Keras','csbdeep']:\n",
    "    find_name=all_packages.find(name)\n",
    "    main_packages = main_packages+all_packages[find_name:all_packages.find(',',find_name)]+', '\n",
    "    #Version numbers only here:\n",
    "    version_numbers.append(all_packages[find_name+len(name)+2:all_packages.find(',',find_name)])\n",
    "\n",
    "  cuda_version = subprocess.run('nvcc --version',stdout=subprocess.PIPE, shell=True)\n",
    "  cuda_version = cuda_version.stdout.decode('utf-8')\n",
    "  cuda_version = cuda_version[cuda_version.find(', V')+3:-1]\n",
    "  gpu_name = subprocess.run('nvidia-smi',stdout=subprocess.PIPE, shell=True)\n",
    "  gpu_name = gpu_name.stdout.decode('utf-8')\n",
    "  gpu_name = gpu_name[gpu_name.find('Tesla'):gpu_name.find('Tesla')+10]\n",
    "  #print(cuda_version[cuda_version.find(', V')+3:-1])\n",
    "  #print(gpu_name)\n",
    "\n",
    "  shape = io.imread(Training_source+'/'+os.listdir(Training_source)[1]).shape\n",
    "  dataset_size = len(os.listdir(Training_source))\n",
    "\n",
    "  text = 'The '+Network+' model was trained from scratch for '+str(number_of_epochs)+' epochs on '+str(dataset_size)+' paired image patches (image dimensions: '+str(shape)+', patch size: ('+str(patch_size)+','+str(patch_size)+')) with a batch size of '+str(batch_size)+' and a '+conf.train_dist_loss+' loss function, using the '+Network+' ZeroCostDL4Mic notebook (v '+Notebook_version[0]+') (von Chamier & Laine et al., 2020). Key python packages used include tensorflow (v '+version_numbers[0]+'), Keras (v '+version_numbers[2]+'), csbdeep (v '+version_numbers[3]+'), numpy (v '+version_numbers[1]+'), cuda (v '+cuda_version+'). The training was accelerated using a '+gpu_name+'GPU.'\n",
    "\n",
    "  #text = 'The '+Network+' model ('+model_name+') was trained using '+str(dataset_size)+' paired images (image dimensions: '+str(shape)+') using the '+Network+' ZeroCostDL4Mic notebook (v '+Notebook_version[0]+') (von Chamier & Laine et al., 2020). Key python packages used include tensorflow (v '+version_numbers[0]+'), Keras (v '+version_numbers[2]+'), csbdeep (v '+version_numbers[3]+'), numpy (v '+version_numbers[1]+'), cuda (v '+cuda_version+'). The GPU used was a '+gpu_name+'.'\n",
    "\n",
    "  if pretrained_model:\n",
    "    text = 'The '+Network+' model was trained for '+str(number_of_epochs)+' epochs on '+str(dataset_size)+' paired image patches (image dimensions: '+str(shape)+', patch size: ('+str(patch_size)+','+str(patch_size)+')) with a batch size of '+str(batch_size)+' and a '+conf.train_dist_loss+' loss function, using the '+Network+' ZeroCostDL4Mic notebook (v '+Notebook_version[0]+') (von Chamier & Laine et al., 2020). The model was retrained from a pretrained model. Key python packages used include tensorflow (v '+version_numbers[0]+'), Keras (v '+version_numbers[2]+'), csbdeep (v '+version_numbers[3]+'), numpy (v '+version_numbers[1]+'), cuda (v '+cuda_version+'). The training was accelerated using a '+gpu_name+'GPU.'\n",
    "\n",
    "  pdf.set_font('')\n",
    "  pdf.set_font_size(10.)\n",
    "  pdf.multi_cell(190, 5, txt = text, align='L')\n",
    "  pdf.set_font('')\n",
    "  pdf.set_font('Arial', size = 10, style = 'B')\n",
    "  pdf.ln(1)\n",
    "  pdf.cell(28, 5, txt='Augmentation: ', ln=0)\n",
    "  pdf.set_font('')\n",
    "  if augmentation:\n",
    "    aug_text = 'The dataset was augmented by a factor of '+str(Multiply_dataset_by)\n",
    "    \n",
    "  else:\n",
    "    aug_text = 'No augmentation was used for training.'\n",
    "  pdf.multi_cell(190, 5, txt=aug_text, align='L')\n",
    "  pdf.set_font('Arial', size = 11, style = 'B')\n",
    "  pdf.ln(1)\n",
    "  pdf.cell(180, 5, txt = 'Parameters', align='L', ln=1)\n",
    "  pdf.set_font('')\n",
    "  pdf.set_font_size(10.)\n",
    "  if Use_Default_Advanced_Parameters:\n",
    "    pdf.cell(200, 5, txt='Default Advanced Parameters were enabled')\n",
    "  pdf.cell(200, 5, txt='The following parameters were used for training:')\n",
    "  pdf.ln(1)\n",
    "  html = \"\"\" \n",
    "  <table width=40% style=\"margin-left:0px;\">\n",
    "    <tr>\n",
    "      <th width = 50% align=\"left\">Parameter</th>\n",
    "      <th width = 50% align=\"left\">Value</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td width = 50%>number_of_epochs</td>\n",
    "      <td width = 50%>{0}</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td width = 50%>patch_size</td>\n",
    "      <td width = 50%>{1}</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td width = 50%>batch_size</td>\n",
    "      <td width = 50%>{2}</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td width = 50%>number_of_steps</td>\n",
    "      <td width = 50%>{3}</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td width = 50%>percentage_validation</td>\n",
    "      <td width = 50%>{4}</td>\n",
    "    </tr>\n",
    "      <tr>\n",
    "      <td width = 50%>n_rays</td>\n",
    "      <td width = 50%>{5}</td>\n",
    "    </tr>\n",
    "      <tr>\n",
    "      <td width = 50%>grid_parameter</td>\n",
    "      <td width = 50%>{6}</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td width = 50%>initial_learning_rate</td>\n",
    "      <td width = 50%>{7}</td>\n",
    "    </tr>\n",
    "  </table>\n",
    "  \"\"\".format(number_of_epochs,str(patch_size)+'x'+str(patch_size),batch_size,number_of_steps,percentage_validation,n_rays,grid_parameter,initial_learning_rate)\n",
    "  pdf.write_html(html)\n",
    "\n",
    "  #pdf.multi_cell(190, 5, txt = text_2, align='L')\n",
    "  pdf.set_font(\"Arial\", size = 11, style='B')\n",
    "  pdf.ln(1)\n",
    "  pdf.cell(190, 5, txt = 'Training Dataset', align='L', ln=1)\n",
    "  pdf.set_font('')\n",
    "  pdf.set_font('Arial', size = 10, style = 'B')\n",
    "  pdf.cell(30, 5, txt= 'Training_source:', align = 'L', ln=0)\n",
    "  pdf.set_font('')\n",
    "  pdf.multi_cell(170, 5, txt = Training_source, align = 'L')\n",
    "  pdf.set_font('')\n",
    "  pdf.set_font('Arial', size = 10, style = 'B')\n",
    "  pdf.cell(28, 5, txt= 'Training_target:', align = 'L', ln=0)\n",
    "  pdf.set_font('')\n",
    "  pdf.multi_cell(170, 5, txt = Training_target, align = 'L')\n",
    "  #pdf.cell(190, 5, txt=aug_text, align='L', ln=1)\n",
    "  pdf.ln(1)\n",
    "  pdf.set_font('')\n",
    "  pdf.set_font('Arial', size = 10, style = 'B')\n",
    "  pdf.cell(21, 5, txt= 'Model Path:', align = 'L', ln=0)\n",
    "  pdf.set_font('')\n",
    "  pdf.multi_cell(170, 5, txt = model_path+'/'+model_name, align = 'L')\n",
    "  pdf.ln(1)\n",
    "  pdf.cell(60, 5, txt = 'Example Training pair', ln=1)\n",
    "  pdf.ln(1)\n",
    "  exp_size = io.imread('/content/TrainingDataExample_StarDist2D.png').shape\n",
    "  pdf.image('/content/TrainingDataExample_StarDist2D.png', x = 11, y = None, w = round(exp_size[1]/8), h = round(exp_size[0]/8))\n",
    "  pdf.ln(1)\n",
    "  ref_1 = 'References:\\n - ZeroCostDL4Mic: von Chamier, Lucas & Laine, Romain, et al. \"Democratising deep learning for microscopy with ZeroCostDL4Mic.\" Nature Communications (2021).'\n",
    "  pdf.multi_cell(190, 5, txt = ref_1, align='L')\n",
    "  ref_2 = '- StarDist 2D: Schmidt, Uwe, et al. \"Cell detection with star-convex polygons.\" International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, Cham, 2018.'\n",
    "  pdf.multi_cell(190, 5, txt = ref_2, align='L')\n",
    "  if augmentation:\n",
    "    ref_4 = '- Augmentor: Bloice, Marcus D., Christof Stocker, and Andreas Holzinger. \"Augmentor: an image augmentation library for machine learning.\" arXiv preprint arXiv:1708.04680 (2017).'\n",
    "    pdf.multi_cell(190, 5, txt = ref_4, align='L')\n",
    "  pdf.ln(3)\n",
    "  reminder = 'Important:\\nRemember to perform the quality control step on all newly trained models\\nPlease consider depositing your training dataset on Zenodo'\n",
    "  pdf.set_font('Arial', size = 11, style='B')\n",
    "  pdf.multi_cell(190, 5, txt=reminder, align='C')\n",
    "\n",
    "  pdf.output(model_path+'/'+model_name+'/'+model_name+\"_training_report.pdf\")\n",
    "\n",
    "\n",
    "def qc_pdf_export():\n",
    "  class MyFPDF(FPDF, HTMLMixin):\n",
    "      pass\n",
    "\n",
    "  pdf = MyFPDF()\n",
    "  pdf.add_page()\n",
    "  pdf.set_right_margin(-1)\n",
    "  pdf.set_font(\"Arial\", size = 11, style='B') \n",
    "\n",
    "  Network = 'Stardist 2D'\n",
    "\n",
    "  day = datetime.now()\n",
    "  datetime_str = str(day)[0:10]\n",
    "\n",
    "  Header = 'Quality Control report for '+Network+' model ('+QC_model_name+')\\nDate: '+datetime_str\n",
    "  pdf.multi_cell(180, 5, txt = Header, align = 'L') \n",
    "\n",
    "  all_packages = ''\n",
    "  for requirement in freeze(local_only=True):\n",
    "    all_packages = all_packages+requirement+', '\n",
    "\n",
    "  pdf.set_font('')\n",
    "  pdf.set_font('Arial', size = 11, style = 'B')\n",
    "  pdf.ln(2)\n",
    "  pdf.cell(190, 5, txt = 'Development of Training Losses', ln=1, align='L')\n",
    "  pdf.ln(1)\n",
    "  exp_size = io.imread(full_QC_model_path+'/Quality Control/lossCurvePlots.png').shape\n",
    "  if os.path.exists(full_QC_model_path+'/Quality Control/lossCurvePlots.png'):\n",
    "    pdf.image(full_QC_model_path+'/Quality Control/lossCurvePlots.png', x = 11, y = None, w = round(exp_size[1]/8), h = round(exp_size[0]/8))\n",
    "  else:\n",
    "    pdf.set_font('')\n",
    "    pdf.set_font('Arial', size=10)\n",
    "    pdf.multi_cell(190, 5, txt='If you would like to see the evolution of the loss function during training please play the first cell of the QC section in the notebook.')\n",
    "  pdf.ln(2)\n",
    "  pdf.set_font('')\n",
    "  pdf.set_font('Arial', size = 10, style = 'B')\n",
    "  pdf.ln(3)\n",
    "  pdf.cell(80, 5, txt = 'Example Quality Control Visualisation', ln=1)\n",
    "  pdf.ln(1)\n",
    "  exp_size = io.imread(full_QC_model_path+'/Quality Control/QC_example_data.png').shape\n",
    "  pdf.image(full_QC_model_path+'/Quality Control/QC_example_data.png', x = 16, y = None, w = round(exp_size[1]/10), h = round(exp_size[0]/10))\n",
    "  pdf.ln(1)\n",
    "  pdf.set_font('')\n",
    "  pdf.set_font('Arial', size = 11, style = 'B')\n",
    "  pdf.ln(1)\n",
    "  pdf.cell(180, 5, txt = 'Quality Control Metrics', align='L', ln=1)\n",
    "  pdf.set_font('')\n",
    "  pdf.set_font_size(10.)\n",
    "\n",
    "  pdf.ln(1)\n",
    "  html = \"\"\"\n",
    "  <body>\n",
    "  <font size=\"7\" face=\"Courier New\" >\n",
    "  <table width=100% style=\"margin-left:0px;\">\"\"\"\n",
    "  with open(full_QC_model_path+'/Quality Control/Quality_Control for '+QC_model_name+'.csv', 'r') as csvfile:\n",
    "    metrics = csv.reader(csvfile)\n",
    "    header = next(metrics)\n",
    "    #image = header[0]\n",
    "    #PvGT_IoU = header[1]\n",
    "    fp = header[2]\n",
    "    tp = header[3]\n",
    "    fn = header[4]\n",
    "    precision = header[5]\n",
    "    recall = header[6]\n",
    "    acc = header[7]\n",
    "    f1 = header[8]\n",
    "    n_true = header[9]\n",
    "    n_pred = header[10]\n",
    "    mean_true = header[11]\n",
    "    mean_matched = header[12]\n",
    "    panoptic = header[13]\n",
    "    header = \"\"\"\n",
    "    <tr>\n",
    "    <th width = 5% align=\"center\">{0}</th>\n",
    "    <th width = 12% align=\"center\">{1}</th>\n",
    "    <th width = 6% align=\"center\">{2}</th>\n",
    "    <th width = 6% align=\"center\">{3}</th>\n",
    "    <th width = 6% align=\"center\">{4}</th>\n",
    "    <th width = 5% align=\"center\">{5}</th>\n",
    "    <th width = 5% align=\"center\">{6}</th>\n",
    "    <th width = 5% align=\"center\">{7}</th>\n",
    "    <th width = 5% align=\"center\">{8}</th>\n",
    "    <th width = 5% align=\"center\">{9}</th>\n",
    "    <th width = 5% align=\"center\">{10}</th>\n",
    "    <th width = 10% align=\"center\">{11}</th>\n",
    "    <th width = 11% align=\"center\">{12}</th>\n",
    "    <th width = 11% align=\"center\">{13}</th>\n",
    "    </tr>\"\"\".format(\"image #\",\"Prediction v. GT IoU\",'false pos.','true pos.','false neg.',precision,recall,acc,f1,n_true,n_pred,mean_true,mean_matched,panoptic)\n",
    "    html = html+header\n",
    "    i=0\n",
    "    for row in metrics:\n",
    "      i+=1\n",
    "      #image = row[0]\n",
    "      PvGT_IoU = row[1]\n",
    "      fp = row[2]\n",
    "      tp = row[3]\n",
    "      fn = row[4]\n",
    "      precision = row[5]\n",
    "      recall = row[6]\n",
    "      acc = row[7]\n",
    "      f1 = row[8]\n",
    "      n_true = row[9]\n",
    "      n_pred = row[10]\n",
    "      mean_true = row[11]\n",
    "      mean_matched = row[12]\n",
    "      panoptic = row[13]\n",
    "      cells = \"\"\"\n",
    "        <tr>\n",
    "          <td width = 5% align=\"center\">{0}</td>\n",
    "          <td width = 12% align=\"center\">{1}</td>\n",
    "          <td width = 6% align=\"center\">{2}</td>\n",
    "          <td width = 6% align=\"center\">{3}</td>\n",
    "          <td width = 6% align=\"center\">{4}</td>\n",
    "          <td width = 5% align=\"center\">{5}</td>\n",
    "          <td width = 5% align=\"center\">{6}</td>\n",
    "          <td width = 5% align=\"center\">{7}</td>\n",
    "          <td width = 5% align=\"center\">{8}</td>\n",
    "          <td width = 5% align=\"center\">{9}</td>\n",
    "          <td width = 5% align=\"center\">{10}</td>\n",
    "          <td width = 10% align=\"center\">{11}</td>\n",
    "          <td width = 11% align=\"center\">{12}</td>\n",
    "          <td width = 11% align=\"center\">{13}</td>\n",
    "        </tr>\"\"\".format(str(i),str(round(float(PvGT_IoU),3)),fp,tp,fn,str(round(float(precision),3)),str(round(float(recall),3)),str(round(float(acc),3)),str(round(float(f1),3)),n_true,n_pred,str(round(float(mean_true),3)),str(round(float(mean_matched),3)),str(round(float(panoptic),3)))\n",
    "      html = html+cells\n",
    "    html = html+\"\"\"</body></table>\"\"\"\n",
    "    \n",
    "  pdf.write_html(html)\n",
    "\n",
    "  pdf.ln(1)\n",
    "  pdf.set_font('')\n",
    "  pdf.set_font_size(10.)\n",
    "  ref_1 = 'References:\\n - ZeroCostDL4Mic: von Chamier, Lucas & Laine, Romain, et al. \"Democratising deep learning for microscopy with ZeroCostDL4Mic.\" Nature Communications (2021).'\n",
    "  pdf.multi_cell(190, 5, txt = ref_1, align='L')\n",
    "  ref_2 = '- StarDist 2D: Schmidt, Uwe, et al. \"Cell detection with star-convex polygons.\" International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer, Cham, 2018.'\n",
    "  pdf.multi_cell(190, 5, txt = ref_2, align='L')\n",
    "\n",
    "  pdf.ln(3)\n",
    "  reminder = 'To find the parameters and other information about how this model was trained, go to the training_report.pdf of this model which should be in the folder of the same name.'\n",
    "\n",
    "  pdf.set_font('Arial', size = 11, style='B')\n",
    "  pdf.multi_cell(190, 5, txt=reminder, align='C')\n",
    "\n",
    "  pdf.output(full_QC_model_path+'/Quality Control/'+QC_model_name+'_QC_report.pdf')\n",
    "\n",
    "# Build requirements file for local run\n",
    "after = [str(m) for m in sys.modules]\n",
    "build_requirements_file(before, after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d8wuQGjoq6eN"
   },
   "source": [
    "\n",
    "\n",
    "## **Generate prediction(s) from unseen dataset**\n",
    "---\n",
    "\n",
    "<font size = 4>In this section the unseen data is processed using the trained model. First, your unseen images are uploaded and prepared for prediction. \n",
    "---\n",
    "\n",
    "<font size = 4>The current trained model can now be used to process images. If an older model needs to be used, please untick the **Use_the_current_trained_model** box and enter the name and path of the model to use. Predicted output images are saved in your **Prediction_folder** folder as restored image stacks (ImageJ-compatible TIFF images).\n",
    "\n",
    "<font size = 4>**`Data_folder`:** This folder should contains the images that you want to predict using the network that you will train.\n",
    "\n",
    "<font size = 4>**`Result_folder`:** This folder will contain the predicted output ROI.\n",
    "\n",
    "<font size = 4>**`Data_type`:** Please indicate if the images you want to predict are single images or stacks\n",
    "\n",
    "\n",
    "<font size = 4>In stardist the following results can be exported:\n",
    "- Region of interest (ROI) that can be opened in ImageJ / Fiji. The ROI are saved inside of a .zip file in your choosen result folder. To open the ROI in Fiji, just drag and drop the zip file !**\n",
    "- The predicted mask images\n",
    "- A tracking file that can easily be imported into Trackmate to track the nuclei.\n",
    "- A CSV file that contains the number of nuclei detected per image. \n",
    "- A CSV file that contains the coordinate the centre of each detected nuclei (single image only). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "15qY7ooyuMFa5DcxVUwbt-tZWi3BrwCnX"
    },
    "executionInfo": {
     "elapsed": 5012798,
     "status": "ok",
     "timestamp": 1637589885021,
     "user": {
      "displayName": "PABLO DELGADO RODRIGUEZ",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "11999848093282927146"
     },
     "user_tz": -60
    },
    "id": "y2TD5p7MZrEb",
    "outputId": "409acbcc-522a-4e44-f5ae-af17643b7679"
   },
   "outputs": [],
   "source": [
    "#This cell is for prediction on your own data\n",
    "\n",
    "\n",
    "\n",
    "# Provide the path to your dataset and to the folder where the prediction will be saved (Result folder), then play the cell to predict output on your unseen images.\n",
    "#C01 is the lectin channel (the one we are interested in)\n",
    "\n",
    "#This is the path to a single tile folder. You need to\n",
    "#Data_folder = '//10.117.178.19/SharedData/AAV para enfermedades renales/MacroSPIM2 (drive)'+\\\n",
    "#'/KidneyR2Right_LectinRed_RLSamples2021/All/RL00--X00--Y00--C00'\n",
    "\n",
    "Data_folder = 'E:/AAV para enfermedades renales/LSFM combined images/R2LEC-Path_SRL'\n",
    "\n",
    "#Data_folder = 'E:/MacroSPIM/Kidney1_derecho_4.8x_1x3_R&Lshifted1.6mm/RL01--X00--Y03--C01'\n",
    "#Data_folder = \"D:/AAV para enfermedades renales/Stardist glomeruli/Stardist results on whole image/Small image Brightness Correction/RL01--X00--Y00--C01\"\n",
    "\n",
    "#Specify only the results folder for the whole large image, the different tiles' folders will be created\n",
    "#Results_folder = '//10.117.178.19/SharedData/AAV para enfermedades renales/MacroSPIM2 (drive)'+\\\n",
    "#'/KidneyR2Right_LectinRed_RLSamples2021/KidneyR2Right_LectinRed_RLSamples2021-GlomeruliSegmentation'\n",
    "\n",
    "#Results_folder = \"D:/AAV para enfermedades renales/Stardist glomeruli/Stardist results on whole image/Result on large image/Kidney1_derecho_4.8x_1x3_R&Lshifted1.6mm\"\n",
    "Results_folder = 'E:/AAV para enfermedades renales/LSFM combined images/'+\\\n",
    "'Results-GlomeruliSeg'\n",
    "\n",
    "import os\n",
    "\n",
    "Single_Images = 1\n",
    "Stacks = 2\n",
    "\n",
    "Results_folder= Results_folder + '/' + os.path.basename(Data_folder)\n",
    "\n",
    "if not os.path.exists(Results_folder):\n",
    "    os.makedirs(Results_folder)\n",
    "    \n",
    "\n",
    "#Are your data single images or stacks? The options are [\"Single_Images\", \"Stacks\"]\n",
    "\n",
    "Data_type = Single_Images \n",
    "\n",
    "#What outputs would you like to generate?\n",
    "Region_of_interests = False \n",
    "Mask_images = True \n",
    "Tracking_file = False \n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "#How many images you want to analyze from the folder? (0 means all of them)\n",
    "\n",
    "numImages =  0#@param {type:\"number\"}\n",
    "\n",
    "#Whether you want to invert the image colors or not\n",
    "invert = False\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "# model name and path\n",
    "#Do you want to use the current trained model?\n",
    "Use_the_current_trained_model = False \n",
    "\n",
    "#If not, please provide the path to the model folder:\n",
    "\n",
    "Prediction_model_folder = 'E:/AAV para enfermedades renales/Stardist glomeruli/'+\\\n",
    "'Stardist results on whole image/glomModelIlumCorrected5'\n",
    "\n",
    "\n",
    "\n",
    "#Here we find the loaded model name and parent path\n",
    "Prediction_model_name = os.path.basename(Prediction_model_folder)\n",
    "Prediction_model_path = os.path.dirname(Prediction_model_folder)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if (Use_the_current_trained_model): \n",
    "  print(\"Using current trained network\")\n",
    "  Prediction_model_name = model_name\n",
    "  Prediction_model_path = model_path\n",
    "\n",
    "full_Prediction_model_path = Prediction_model_path+'/'+Prediction_model_name+'/'\n",
    "if os.path.exists(full_Prediction_model_path):\n",
    "  print(\"The \"+Prediction_model_name+\" network will be used.\")\n",
    "else:\n",
    "  print(bcolors.WARNING+'!! WARNING: The chosen model does not exist !!'+W)\n",
    "  print('Please make sure you provide a valid model path and model name before proceeding further.')\n",
    "\n",
    "#single images\n",
    "\n",
    "if Data_type == 1 :\n",
    "\n",
    "  Data_folder = Data_folder+\"/*.tif\"\n",
    "\n",
    "  print(\"Single images are now beeing predicted\")\n",
    "  np.random.seed(16)\n",
    "  lbl_cmap = random_label_cmap()\n",
    "  X = sorted(glob(Data_folder))\n",
    "  print(X)\n",
    "  #~~~~~~~~~~~~~~~~~~\n",
    "  #X = list(map(imread,X))\n",
    "  #~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "  print('Total number of images: ',len(X))\n",
    "\n",
    "  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "  #Here we find the images already created in a previous run\n",
    "  prevCreatedNames = [os.path.basename(f) for f in sorted(glob(Results_folder+'/*.tif'))]\n",
    "\n",
    "  prevCreatedFILEnames = []\n",
    "  for m in prevCreatedNames:\n",
    "    m = Results_folder+'/'+m\n",
    "    prevCreatedFILEnames.append(m)\n",
    "  \n",
    "  #Get rid of the first image names (already predicted)\n",
    "  X = X[len(prevCreatedFILEnames):]\n",
    "\n",
    "  print('Number of images to be predicted: ',numImages)\n",
    "  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "  n_channel = 1 \n",
    "\n",
    "  #~~~~~~~~~~~~~~~~~~~~\n",
    "  n_channel = 1 if imread(X[0]).ndim == 2 else imread(X[0]).shape[-1]\n",
    "  #~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "  # axis_norm = (0,1,2) # normalize channels jointly\n",
    "  if n_channel == 1:\n",
    "    axis_norm = (0,1)   # normalize channels independently\n",
    "    print(\"Normalizing image channels independently\")\n",
    "\n",
    "  if n_channel > 1:\n",
    "    axis_norm = (0,1,2) # normalize channels jointly\n",
    "    print(\"Normalizing image channels jointly\")  \n",
    "    sys.stdout.flush()  \n",
    "  \n",
    "  model = StarDist2D(None, name = Prediction_model_name, basedir = Prediction_model_path)\n",
    " \n",
    "\n",
    "  names = [os.path.basename(f) for f in sorted(glob(Data_folder))[len(prevCreatedFILEnames):]]  \n",
    "  Nuclei_number = []\n",
    "\n",
    "\n",
    "\n",
    "  # modify the names to suitable form: path_images/image_numberX.tif\n",
    "  FILEnames = []\n",
    "  for m in names:\n",
    "    m = Results_folder+'/'+m\n",
    "    FILEnames.append(m)\n",
    "\n",
    "  # Create a list of name with no extension\n",
    " \n",
    "  name_no_extension=[]\n",
    "  for n in names:\n",
    "    name_no_extension.append(os.path.splitext(n)[0])\n",
    "\n",
    "\n",
    "  # Save all ROIs and masks into results folder\n",
    "  \n",
    "  for i in range(len(X)):\n",
    "\n",
    "      #~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "      origIm = imread(X[i])\n",
    "\n",
    "      if invert == True:\n",
    "        origIm = np.abs(origIm-np.max(origIm))\n",
    "      #~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "      img = normalize(origIm, 1,99.8, axis = axis_norm)\n",
    "      labels, polygons = model.predict_instances(img)\n",
    "      \n",
    "      #print(i)\n",
    "\n",
    "      os.chdir(Results_folder)\n",
    "\n",
    "      if Mask_images:\n",
    "        #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "        \n",
    "        #Reduce the bit depth of the result\n",
    "        labels = labels.astype(np.uint8)\n",
    "        #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "        print('FILEnames: ',FILEnames)\n",
    "        \n",
    "        imsave(FILEnames[i], labels, polygons)\n",
    "        \n",
    "        #~~~~\n",
    "        print('- image ',i+len(prevCreatedNames),' saved as ',FILEnames[i])\n",
    "        #~~~~\n",
    "\n",
    "      if Region_of_interests:\n",
    "        export_imagej_rois(name_no_extension[i], polygons['coord'])\n",
    "\n",
    "      if Tracking_file:\n",
    "        Tracking_image = np.zeros((img.shape[1], img.shape[0]))\n",
    "        for point in polygons['points']:\n",
    "          cv2.circle(Tracking_image,tuple(point),0,(1), -1)\n",
    "        \n",
    "        Tracking_image_32 = img_as_float32(Tracking_image, force_copy=False)\n",
    "        Tracking_image_8 = img_as_ubyte(Tracking_image, force_copy=True)      \n",
    "        Tracking_image_8_rot = np.rot90(Tracking_image_8, axes=(0, 1))\n",
    "        Tracking_image_8_rot_flip = np.flipud(Tracking_image_8_rot)\n",
    "        imsave(Results_folder+\"/\"+str(name_no_extension[i])+\"_tracking_file.tif\", Tracking_image_8_rot_flip, compress=ZIP_DEFLATED)\n",
    "      \n",
    "      Nuclei_centre_coordinate = polygons['points']\n",
    "      my_df2 = pd.DataFrame(Nuclei_centre_coordinate)\n",
    "      my_df2.columns =['Y', 'X']\n",
    "      \n",
    "      #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "      #Don't store the nuclei centers\n",
    "      #my_df2.to_csv(Results_folder+'/'+name_no_extension[i]+'_Nuclei_centre.csv', index=False, header=True)\n",
    "\n",
    "      #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "      Nuclei_array = polygons['coord']\n",
    "      Nuclei_array2 = [names[i], Nuclei_array.shape[0]]\n",
    "      Nuclei_number.append(Nuclei_array2)\n",
    "\n",
    "      #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "      #If a limit of images was specified (numImages != 0) and this limit has been reached (imCount == numImages)\n",
    "      #stop the loop \n",
    "      if i == numImages-1:\n",
    "        break\n",
    "      #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "  my_df = pd.DataFrame(Nuclei_number)\n",
    "  my_df2.columns =['Frame number', 'Number of objects']\n",
    "  my_df.to_csv(Results_folder+'/Nuclei_count.csv', index=False, header=False)\n",
    "  \n",
    "# One example is displayed\n",
    "\n",
    "  print(\"One example image is displayed bellow:\")\n",
    "  plt.figure(figsize=(10,10))\n",
    "  plt.imshow(img if img.ndim==2 else img[...,:3], clim=(0,1), cmap='gray')\n",
    "  plt.imshow(labels, cmap=lbl_cmap, alpha=0.5)\n",
    "  plt.axis('off');\n",
    "  \n",
    "  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "  #Do not save the image\n",
    "  #plt.savefig(name_no_extension[i]+\"_overlay.tif\")\n",
    "\n",
    "# Here is the code to analyse stacks\n",
    "\n",
    "if Data_type == 2 :\n",
    "  print(\"Stacks are now beeing predicted\")\n",
    "  np.random.seed(42)\n",
    "  lbl_cmap = random_label_cmap()\n",
    "\n",
    "  # normalize channels independently\n",
    "  axis_norm = (0,1)  \n",
    "  \n",
    "  model = StarDist2D(None, name = Prediction_model_name, basedir = Prediction_model_path)\n",
    "  \n",
    "  for image in os.listdir(Data_folder):\n",
    "    print(\"Performing prediction on: \"+image)\n",
    "\n",
    "    Number_of_nuclei_list = []\n",
    "    Number_of_frame_list = []\n",
    "\n",
    "    timelapse = imread(Data_folder+\"/\"+image)\n",
    "\n",
    "    short_name = os.path.splitext(image)     \n",
    "    \n",
    "    timelapse = normalize(timelapse, 1,99.8, axis=(0,)+tuple(1+np.array(axis_norm)))\n",
    "    \n",
    "\n",
    "    if Region_of_interests: \n",
    "      polygons = [model.predict_instances(frame)[1]['coord'] for frame in tqdm(timelapse)]    \n",
    "      export_imagej_rois(Results_folder+\"/\"+str(short_name[0]), polygons, compression=ZIP_DEFLATED)  \n",
    "    \n",
    "    n_timepoint = timelapse.shape[0]\n",
    "    prediction_stack = np.zeros((n_timepoint, timelapse.shape[1], timelapse.shape[2]))\n",
    "    Tracking_stack = np.zeros((n_timepoint, timelapse.shape[2], timelapse.shape[1]))\n",
    "\n",
    "# Analyse each time points one after the other\n",
    "    if Mask_images or Tracking_file:\n",
    "      for t in range(n_timepoint):\n",
    "        img_t = timelapse[t]\n",
    "        labels, polygons = model.predict_instances(img_t)      \n",
    "        prediction_stack[t] = labels\n",
    "        Nuclei_array = polygons['coord']\n",
    "        Nuclei_array2 = [str(t), Nuclei_array.shape[0]]\n",
    "        Number_of_nuclei_list.append(Nuclei_array2)\n",
    "        Number_of_frame_list.append(t)\n",
    "\n",
    "# Create a tracking file for trackmate\n",
    "\n",
    "        for point in polygons['points']:\n",
    "          cv2.circle(Tracking_stack[t],tuple(point),0,(1), -1)\n",
    "\n",
    "      prediction_stack_32 = img_as_float32(prediction_stack, force_copy=False)\n",
    "      Tracking_stack_32 = img_as_float32(Tracking_stack, force_copy=False)\n",
    "      Tracking_stack_8 = img_as_ubyte(Tracking_stack_32, force_copy=True)\n",
    "      \n",
    "      Tracking_stack_8_rot = np.rot90(Tracking_stack_8, axes=(1,2))\n",
    "      Tracking_stack_8_rot_flip = np.fliplr(Tracking_stack_8_rot)\n",
    "\n",
    "# Export a csv file containing the number of nuclei detected at each frame\n",
    "      my_df = pd.DataFrame(Number_of_nuclei_list)\n",
    "      my_df.to_csv(Results_folder+'/'+str(short_name[0])+'_Nuclei_number.csv', index=False, header=False)\n",
    "\n",
    "      os.chdir(Results_folder)\n",
    "      if Mask_images:\n",
    "        imsave(str(short_name[0])+\".tif\", prediction_stack_32, compress=ZIP_DEFLATED)\n",
    "      if Tracking_file:\n",
    "        imsave(str(short_name[0])+\"_tracking_file.tif\", Tracking_stack_8_rot_flip, compress=ZIP_DEFLATED)\n",
    "\n",
    "  # Object detected vs frame number\n",
    "    plt.figure(figsize=(20,5))\n",
    "    my_df.plot()\n",
    "    plt.title('Number of objects vs frame number')\n",
    "    plt.ylabel('Number of detected objects')\n",
    "    plt.xlabel('Frame number')\n",
    "    plt.legend()\n",
    "    plt.savefig(Results_folder+'/'+str(short_name[0])+'_Object_detected_vs_frame_number.png',bbox_inches='tight',pad_inches=0)\n",
    "    plt.show()         \n",
    "\n",
    "print(\"Predictions completed\")   "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyP4XJPxqN4HWdyNp0BFxCTg",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "mount_file_id": "1WThJ75zEMIA84bBivcFlqw0pyBiZNk6-",
   "name": "run_stardist_on_large_images.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
